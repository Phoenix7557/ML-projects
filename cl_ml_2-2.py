# -*- coding: utf-8 -*-
"""CL_ML_2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q1RSmm7SgbBb_zwFwKzTyD3OvX6FCiYd
"""

from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf

import pandas as pd
import numpy as np


from sklearn.preprocessing import StandardScaler
from tensorflow.keras.utils import to_categorical

CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species'] # the features in the data used to determind which class
SPECIES = ['Setosa', 'Versicolor', 'Virginica'] # the classes

train_path =tf.keras.utils.get_file("iris_training.csv", "https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv")
test_path = tf.keras.utils.get_file(
    "iris_test.csv", "https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv")

train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0) # to load the csv file.
test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)

train.head() # just shows the dataframe created with the line train = ... above. used to take a look at the data

train_y = train.pop("Species")
test_y = test.pop("Species") # to remove the lable (species)

train.head() #shows the dataframe without the lable(species)

train_y.head() # shows only the lable

train.shape # shows the shape. in this case, 120 diffrent flowers with 4 diffrent features

# Feature columns describe how to use the input.
my_feature_columns = []
for key in train.keys():
    my_feature_columns.append(tf.feature_column.numeric_column(key=key))
print(my_feature_columns)

# Skaliere die Eingabedaten
scaler = StandardScaler()
train_scaled = scaler.fit_transform(train)
test_scaled = scaler.transform(test)

# One-Hot-Encoding der Zielwerte für Mehrklassige Klassifikation
train_y = to_categorical(train_y, num_classes=3)
test_y = to_categorical(test_y, num_classes=3)

# Keras Modell für Mehrklassige Klassifikation
inputs = {key: tf.keras.layers.Input(shape=(1,), name=key) for key in train.columns}

# Concatenate the inputs into one layer
feature_layer = tf.keras.layers.Concatenate()(list(inputs.values()))

# Add hidden layers
x = tf.keras.layers.Dense(64, activation='relu')(feature_layer)
x = tf.keras.layers.Dense(32, activation='relu')(x)

# Output layer for multi-class classification
output = tf.keras.layers.Dense(3, activation='softmax')(x)  # 3 classes

# Create the Keras model
model = tf.keras.Model(inputs=inputs, outputs=output)

# Compile the model for multi-class classification
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Convert the training data to a dictionary (if necessary)
train_dict = {key: train_scaled[:, i] for i, key in enumerate(train.columns)}

# Train the model directly with the input data
model.fit(train_dict, train_y, epochs=50, batch_size=16)

# Optional: Display the model summary
model.summary()

# scale the traings-data
scaler = StandardScaler()
train_scaled = scaler.fit_transform(train)

# scale the test data with same parameter
test_scaled = scaler.transform(test)

# change the data to a dictionary
train_dict = {key: train_scaled[:, i] for i, key in enumerate(train.columns)}
test_dict = {key: test_scaled[:, i] for i, key in enumerate(test.columns)}

# evaluate the model
eval_result = model.evaluate(test_dict, test_y)

# shows th test accuracy
print('\nTest set accuracy: {accuracy:0.3f}\n'.format(accuracy=eval_result[1]))

# Feature names
features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']

# user input
predict = {}

print("Please type numeric values as prompted.")
for feature in features:
    valid = False
    while not valid:
        val = input(f"{feature}: ")
        #checks if the input is a vaild number (also floats)
        if val.replace('.', '', 1).isdigit():
            predict[feature] = [float(val)]
            valid = True
        else:
            print("Invalid input. Please enter a numeric value.")

# changing the input into a  Numpy-Array
predict_data = {key: np.array([value]) for key, value in predict.items()}  # (1, 4)

# makes the prediction
predictions = model.predict(predict_data)

# makes the class prediction
predicted_class = np.argmax(predictions)  # Index der Klasse mit der höchsten Wahrscheinlichkeit

# probability per class
probabilities = predictions[0]

# output
print(f"Predicted class: {predicted_class}")
print(f"Probability of class 0 (Setosa): {probabilities[0]:.2f}")
print(f"Probability of class 1 (Versicolor): {probabilities[1]:.2f}")
print(f"Probability of class 2 (Virginica): {probabilities[2]:.2f}")